---
title: "Replication of \"Once more on norms and comparison classes\" by Tribushinina (2011, Linguistics)"
author: "Elena Tribushinina (E.Tribushinina@uu.nl)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 4
    toc_float:
      collapsed: false
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

##Introduction

Relative adjectives such as *big* and *small* are context sensitive. The sentence *Timmy is tall* might be judged as true when the context contains 4'9'' Timmy and the rest of his third grade, but false when the context contains Timmy and his three grown siblings. In these two contexts, Timmy's height is being compared to different sets of objects, known as comparison classes. While it has been established that comparison classes are determined by the context, which can manifest both linguistically and extra-linguistically, how exactly the process of forming a representation of a context class occurs, and what type of information goes into these judgments is not settled. Tribushinina (2011) argues that in forming a representation of a comparison class speakers integrate world knowledge with the information they get from the visual context in front of them, operationalized as the pictures displayed in an experimental context.

The stimuli seen were pictures of objects. All the pictures were smaller than the objects of the type depicted in them generally are. Therefore, if participants were using only prior world knowledge about the typical size of these objects, then all of the images should have counted as small. If participants were using only the information from the visual context, then the same number of items should count as big and small, and that number should not differ by object. If, instead, people integrate both these types of knowledge when forming a comparison class, then the mean number of items counted as *small* is predicted to be bigger than the number counted as *big*, and it more prototypically big items ate predicted to count as *small*, and vice versa.


##Methods
Tribushinina had 20 adults do a scalar judgment task. Participants were shown a display of seven items identical except for size, ordered by size, ranging from 1-7 cm in 1 cm increments. There were twelve items shown, four prototypically big (plane, house, elephant, hippo), four prototypically small (chick, baby, mouse, gnome), and four neither prototypically big nor prototypically small (umbrella, balloon, monkey, cake). With each display the participants heard the sentences "Which X do you find big/small" (in Dutch), and were allowed  to select as many or as few items as they wanted. The displays were either ascending (increasing in size from left to right) or descending (increasing in size from right to left). Each item was seen four times, with each adjective, and in each direction, for a total of 48 trials. Additionally there were two pretest items, to introduce the task and make people comfortable with choosing as many items as they want. The pre-trial items were "Which balloons do you find pretty" and "Which cars do you find ugly?".

###Power Analysis

The original effect size was calculated using the formula for Cohen's d: $\frac{m_1-m_2}{SD_{pooled}}$. The $SD_{pooled}$ was calculated using the formula $\sqrt{\frac{SD_1^2 + SD_2^2}{2}}$. 
```{r}
SD_1 = 0.9
SD_2 = 1.3
SD_p = sqrt((SD_1^2 + SD_2^2)/2)
m_1 = 2.6
m_2 = 1.65
c_d = (m_1 - m_2)/SD_p
c_d

```
 A G-power power analysis for a-priori sample size results in a required sample size of 11, 14 or 18 participants for 80%, 90% and 95% respectively. I propose to run 2.5 times the number of participants from the original study, for n = 50.
 
![Power analysis for 80% power](figures/80-percent-screenshot.png)

![Power analysis for 90% power](figures/90-percent-screenshot.png)

![Power analysis for 95% power](figures/95-percent-screenshot.png)




###Planned Sample

I plan to run 50 participants. I will filter these so as to only include native speakers of English. This status will be determined by asking each participant to enter their native language, and excluding those participants who enter something other than English. Since it is a text-box, the data may require cleanup to correct for obvious typos before processing. 


###Materials and Procedure
(These sections are together in the original paper)

>Experiment 1 involved a Scalar Judgment Task (Smith et al. 1986, 1988; Syrett et al. 2006; Syrett 2007). The subjects saw pictures of seven same-kind objects on a computer screen and
heard a question of the type *Welke X vind je groot/klein?* 'Which X do you
find big/small', where X was the name of an object category in plural. On the
descending trials, the test pictures incrementally decreased in vertical size
from 7-1 cm at one centimeter intervals. On the ascending trials, the pictures
increased in vertical size from 1-7 cm at one centimeter intervals (see Figure
1).
Three experimental categories were included in this study: prototypically
big entities (elephants, hippos, houses, planes), prototypically small entities
(babies, chickens, gnomes, mice) and prototype-neutral entities that are not
particularly associated with either *groot* 'big' or *klein* 'small' (balloons, cakes,
monkeys, umbrellas). The selection of test objects was made on the basis of
the previous studies that established which objects are seen as prototypically
big and small in the Dutch culture (Tribushinina 2008b, 2011). Prototype neutral objects
were selected on the basis of two criteria - 1. they are not unequivocally associated
with either *groot* 'big' or *klein* 'small'; and 2. they are equally often dubbed *groot* and *klein* by adults in the Dutch corpora (Corpus of Spoken Dutch, Groningen Corpus, Van Kampen Corpus). It is important to notice that prototypicality is a matter of culturally determined construals rather than objective properties of objects. For instance, entities that are known to be best exemplars of smallness are not necessarily smaller than
prototype-neutral entities. What matters is that certain objects are assigned
the status of best exemplars within a particular language/culture. The effects
of such best exemplars in language use and language development proved
robust (Tribushinina 2008b, 2009a, 2011). This experiment aims to determine
whether prototypicality effects qua best exemplars also affect adults' scalar
judgments.
Each of the 12 object categories was presented in four types of trials: *groot*-descending,
*groot*-ascending, *klein*-descending, *klein*-ascending (cf. Smith
et al. 1986). This produced the total of 48 experimental trials.
The subjects were tested individually in a quiet room. The experiment
started with two pre-test items. The subjects first saw a picture of eleven balloons
of different colors and answered the question *Welke ballonnen vind je mooi?* 'Which balloons do you find pretty?' After that, they saw a picture of six
cars and answered the question *Welke auto's vind je lelijk?* 'Which cars do you
find ugly?' During the pre-test phase, the participants were instructed to point
to the objects on the screen if they thought an object could be assigned the corresponding
property. They were also informed that there was no upper or lower
bound: they were allowed to point to *all* the objects or to *none* of them, if they
found appropriate. After the completion of the pre-test phase, the subjects were
presented with the experimental trials, which were pseudorandomized with
respect to two factors: the side of the relevant pole (left or right) and the adjective
(*groot* or *klein*). Prerecorded audio stimuli (e.g., *Welke olifanten vind je
klein?* 'Which elephants do you find small?') were automatically presented
immediately after the corresponding visual stimulus appeared on the screen.
To keep the scalar judgment process as natural as possible, the subjects were
not instructed to make speeded judgments.
The experimental sessions were videotaped using a JVC Everio Camcorder
and later analyzed using ELAN 3.8.1 software. Two analyses of the data were
conducted. The first is an analysis of the ranges dubbed *groot* 'big' and *klein*
'small' across the three conditions - prototypically big entities, prototypically
small entities and prototype-neutral entities (offline measure). The second is an
analysis of RTs during the scalar judgment process (online measure).

I used the original materials. However, a number of manipulations were necessary. I made a couple of adaptations to the pre-test items, aligning the number of options with the rest of the experiment for ease of coding. The other adaptation I made was to the sizing of the stimuli. The original materials has a picture containing all seven images of the display. I took the biggest image of each set, made sure it was sized to 7 cm, and then decreased the size incrementally be a cm each time. The images were then also resized proportionally in the experimental display to fit the size of the participants' screens. Their size relative to each other remains the same.

###Procedure	

The original experiment was conducted in the lab, and had people point to the pictures, and recorded their choices on video. Since my replication is being conducted on Mechanical Turk, a number of adaptations were necessary. The first adaptation is that people click on the pictures to select them rather than point at them. This renders video collection unnecessary. Additionally, the replication uses English instead of Dutch. The effect found is predicted to be present regardless of the language. I recorded my stimuli using an automatic text-to-speech generator (https://text-to-speech-demo.mybluemix.net/), in order to preserve consistent prosody across the stimuli, as opposed to the original stimuli which were recorded by a person. I measured reaction times from the onset of the adjective until the first click on a checkbox, as opposed to the original measurement of until the first pointing move. My experiment can be found at:
http://stanford.edu/~skessler/trib2011_rep/study1.html

###Analysis Plan

The original study looked at peoples pointing gestures. Due to the clicking nature of my task, I will institute a policy regarding the possible ways people could try to game my experiment. There are two unexpected patterns to look for in the data. The first is non-continuous answer sets. If participants, in answering the question *Which balloons do you find small?* select the smallest and then the third and fourth, skipping the second balloon, this is an indication that either they were not paying attention, or that they are not doing the task. I propose to exclude all trials in which there are non-continuous answers (this seems safer than trying to guess which was the reason and filling in the seemingly missing data points),  and exclude any participant who made this mistake on more than 10% of the trials. The second unexpected pattern is answer sets with no endpoint. If a participant did not select the biggest item as *big* but did select other items, it seems possible to be caused by either off the reasons above. I thus propose a similar policy, of excluding all trials with no endpoint and excluding any participant who gave such answers for more than 10% of the trials. Neither of these exclusions are brought up in the original paper, but I think that due to the differences between the laboratory setting and the Mechanical Turk setup, safeguards to gaming the experiment should be instituted.

The key statistical test in this experiment is the Wilcoxon signed rank test showing that "the zone labeled *klein* was significantly larger than the *groot* zone: Z = 3.1, p < .005. This finding corroborates the hypothesis that subjects compute norms using, at least, two kinds of information - a contextually given comparison class (i.e., visually presented series) and their world knowledge of average object sizes in reality."

Additionally,  I will test the differences in mean number of items counted as *big* and *small* for items of each prototype status, using a Freidman test for the overall differences between conditions and then pair-wise Wilcoxon tests for between big and neutral, neutral and small, and big and small objects for each adjective. The prediction is that the *big* zone is bigger for prototypically small objects, and smallest for prototypically big objects, and conversely for the *small* zone. The intuition is that you have to be bigger to count as a *big* big thing than as a *big* small thing.

Finally, I will analyze the reaction times (RTs). The finding in Tribushinina (2011) was 

>"Although reactions to prototype-incompatible questions (e.g., Which elephants
do you find small? / Which mice do you find big?) took slightly longer
than reactions to prototype-compatible questions (e.g., Which elephants do you
find big? / Which mice do you find small?), the difference was only significant
for *groot*: Z = 2.7, p < .05, but not for *klein*: p = .12 (Wilcoxon Singed-ranks
test)."

Additionally, Tribushinina tested whether the RTs for the adjective *small* were different than for *big*, with the prediction that the former has greater cognitive complexity and therefore should take longer to process, however no effect was found. Then she tested whether there was an effect of scale direction and found that there was a difference between ascending and descending trials in the case of *small* but not in the case of *big* suggesting that this might be an expression of the greater cognitive complexity of *small*.

  

###Differences from Original Study

The original study was run in a laboratory setting. The participants saw the images on a screen and pointed to select. This gave them the option of not pointing in order to select none. The participants were recorded in video, and the video was analyzed for the RT measures, and to code their selections.

My replication differs in setting. It will be conducted on Mechanical Turk. Whereas in the lab, it was known that all participants saw the same exact images, in the replication each participant has a screen of different size, so that the images might be of different actual sizes. However, the relative size of the images to each other, and the images across trials should be preserved, so it should not have an effect of the results. However, I will exclude participants who self report that they did the task on a mobile phone or tablet (screen_size smaller than 12 inches). The change in setting also necessitates additional exclusion criteria. Since there is no experimenter present, it is necessary to ensure that participants were not clicking at random. Additionally, since they are clicking and not pointing, it is easy to not be paying close attention, and think you clicked on an image, without it registering. Therefore, I will exclude all trials in which a no-consecutive set of images was selected, and all trials in which no endpoint was selected, or the incorrect endpoint was selected (e.g., if the question was which are big, and the smallest image was selected, but not the biggest). I will also exclude participants who had more than 10% of their trials excluded for any of the above three reasons.


<!-- ### Methods Addendum (Post Data Collection) -->

<!-- You can comment this section out prior to final report with data collection. -->

<!-- #### Actual Sample -->
<!--   Sample size, demographics, data exclusions based on rules spelled out in analysis plan -->

<!-- #### Differences from pre-data collection methods plan -->
<!--   Any differences from what was described as the original plan, or “none”. -->


##Results


### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
###Data Preparation

####Load Relevant Libraries and Functions
library(tidyverse)
#library(langcog)
library(stringr)
library(rjson)

sem <- function(x) {sd(x, na.rm=TRUE) / sqrt(length(x))}
ci95 <- function(x) {sem(x) * 1.96}
addnas <- function (x) {if (length(x)==0){
  result = NA
} else {result = x}
  return(result)
}

####Import data

path <- "D:/Dropbox/School/2016-2017/psych254/Tribushinina2011/data/"
files <- dir("D:/Dropbox/School/2016-2017/psych254/Tribushinina2011/data/anonymized-results/", 
             pattern = "*.json")
d.raw <- data.frame()

for (f in files) {
  jf <- paste0(path, "anonymized-results/",f)
  jd <- fromJSON(file = jf)
  id <- data.frame(subid = f,
                   adj = jd$answers$data$adj,
                   verb = jd$answers$data$verb,
                   noun = jd$answers$data$noun,
                   dir = jd$answers$data$dir,
                   num_checked = as.numeric(jd$answers$data$num_checked),
                   noun = jd$answers$data$noun,
                   elapsed_ms = jd$answers$data$elapsed_ms,
                   elapsed_first_click_ms = jd$answers$data$elapsed_first_click_ms,
                   workerid = jd$WorkerId,
                   language = tolower(jd$answers$data$lang),
                   prototype_status = jd$answers$data$prototype_status,
                   non_consec = jd$answers$data$non_consecutive,
                   is_endpoint = jd$answers$data$is_endpoint,
                   endpoint = as.character(unlist(jd$answer$data$endpoint)),
                   good_endpoint = jd$answers$data$good_ep,
                   none_checked = jd$answer$data$none_checked,
                   screen_size = as.numeric(jd$answer$data$screen_size))
                    
                  
  d.raw <- bind_rows(d.raw, id)
}

# Number of participants
length(unique(d.raw$workerid))
length(unique(d.raw$subid))

num_trials = 48

#### Data exclusion / filtering

# get rid of training items, exclude non-English speakers, exclude those described below

d <- filter(d.raw, prototype_status != "na") %>%
  #filter(verb == "find") %>%
  filter(as.numeric(screen_size) >= 12) %>%
  filter(str_detect(language, 'eng')) %>%
  select(-language) %>%
  group_by(subid) %>%
  mutate(perc_non_consec = sum(non_consec)/num_trials,
            perc_no_endpoint = (length(is_endpoint)-sum(is_endpoint))/num_trials,
         perc_good_endpoint = (sum(good_endpoint))/num_trials) %>%
  filter(perc_non_consec < .1) %>%
  #filter(perc_good_endpoint >.9) %>%
  #filter(good_endpoint == TRUE) %>%
  filter(non_consec == FALSE) %>%
  filter(is_endpoint == TRUE)
for (i in 1:length(d$none_checked)) {
   if (d$none_checked[i] == TRUE & (!is.na(d$none_checked[i]))){
   d$num_checked[i] = 0
   }
 }


#for pilot A
# d <- filter(d.raw, prototype_status != "na") %>%
#   group_by(subid) %>%
#   mutate(perc_non_consec = sum(non_consec)/num_trials,
#             perc_no_endpoint = (length(is_endpoint)-sum(is_endpoint))/num_trials,
#          perc_good_endpoint = (sum(good_endpoint))/num_trials) 

#need to check for having more than 10% non_consecutive or less than 90% with the right endpoint, and exclude those participants, and then exclude any remaining trials in which there is non_consecutive data or no endpoint.  (The option for saying none of them is big is coded as 9, so that if someone checks both the none box and one of the images then it comes up as non-consecutive)

head(d)

#### Prepare data for analysis - create columns etc.
```

### Confirmatory analysis
#### Key test
```{r}
#The mean zone for each adjective -- equivalent to Table 1
d %>%
  group_by(verb, adj) %>%
  summarise(mean_zone = mean(num_checked), sds = sd(num_checked))


```

![Table 1 from Tribushinina, comparing the mean number of items selected for each adjective](figures/trib-tab-1-mean-zones.png)

The  **key test** compares the size of the *big* zone and the *small* zone:
```{r}
#The key analysis -- testing whether the small zone is bigger than the big zone
d_wilc <- d %>%
  group_by(subid, verb, noun, adj, dir) %>%
  summarise(zone = num_checked)%>%
  spread(adj, zone)
  wilcox.test(d_wilc$big, d_wilc$small, alternative = "l", paired = TRUE)
```

####Differences between items of different prototypicality status for each adjective

```{r}

d_graph <- d %>%
  group_by(prototype_status, adj) %>%
  summarise(mean_zone = mean(num_checked), sems = sem(num_checked), cis = ci95(num_checked))



table(d_graph$adj, d_graph$prototype_status)
str(d_graph)

d_graph$adj <- factor(d_graph$adj)
d_graph$prototype_status <- factor(d_graph$prototype_status)
levels(d_graph$prototype_status)

levels(d_graph$adj)
levels(d_graph$prototype_status)


friedman.test(mean_zone ~ adj | prototype_status, data = d_graph)

#create graph equivalent to figure 2 -- mean number of items labeled for each adjective for each prototypicality status

ggplot(d_graph, aes(x=adj, y=mean_zone, fill = prototype_status)) + geom_bar(stat = "identity", position=position_dodge()) +
    geom_errorbar(aes(ymin=mean_zone-sems, ymax=mean_zone+sems),
                  width=.2, position=position_dodge(.9))

ggplot(d_graph, aes(x=adj, y=mean_zone, fill = prototype_status)) + geom_bar(stat = "identity", position=position_dodge()) +
    geom_errorbar(aes(ymin=mean_zone-cis, ymax=mean_zone+cis),
                  width=.2, position=position_dodge(.9))
```


![Original graph of mean number of items checked for each adjective for each prototypicality group](figures/trib-fig-2.png)

```{r}
# Friedman test of differences between objectss of different prototypicality status when the adjective is big
d_fried <- d %>%
  filter(adj=="big")%>%
  group_by(subid, prototype_status) %>%
  summarise(zone = mean(num_checked))



table(d_fried$subid, d_fried$prototype_status)
str(d_fried)

d_fried$subid <- factor(d_fried$subid)
d_fried$prototype_status <- factor(d_fried$prototype_status)
levels(d_fried$prototype_status)

levels(d_fried$subid)
levels(d_fried$prototype_status)


friedman.test(zone ~ prototype_status  | subid, data = d_fried)
```


```{r}
#test the difference between prototypically big and neutral objects when the adjective is big
d_wilc_bn <- d %>%
  filter(adj == "big")%>%
  filter(prototype_status != "small")%>%
  group_by(subid, verb, prototype_status) %>%
  summarise(zone = mean(num_checked))%>%
  spread(prototype_status, zone)

wilcox.test(d_wilc_bn$big, d_wilc_bn$neither, alternative = "l", paired = TRUE)
```

```{r}
#test the difference between prototypically neither and small objects when the adjective is big
d_wilc_ns <- d %>%
  filter(adj == "big")%>%
  filter(prototype_status != "big")%>%
  group_by(subid, verb, prototype_status) %>%
  summarise(zone = mean(num_checked))%>%
  spread(prototype_status, zone)

wilcox.test(d_wilc_ns$neither, d_wilc_ns$small, alternative = "l", paired = TRUE)
```

```{r}
#test the difference between prototypically big and small objects when the adjective is big
d_wilc_bs <- d %>%
  filter(adj == "big")%>%
  filter(prototype_status != "neither")%>%
  group_by(subid, verb, prototype_status) %>%
  summarise(zone = mean(num_checked))%>%
  spread(prototype_status, zone)

wilcox.test(d_wilc_bs$big, d_wilc_bs$small, alternative = "l", paired = TRUE)
```

```{r}
# Friedman test of differences between objectss of different prototypicality status when the adjective is small
d_fried_s <- d %>%
  filter(adj=="big")%>%
  group_by(subid, prototype_status) %>%
  summarise(zone = mean(num_checked))



table(d_fried_s$subid, d_fried_s$prototype_status)
str(d_fried_s)

d_fried_s$subid <- factor(d_fried_s$subid)
d_fried_s$prototype_status <- factor(d_fried_s$prototype_status)
levels(d_fried_s$prototype_status)

levels(d_fried$subid)
levels(d_fried$prototype_status)


friedman.test(zone ~ prototype_status  | subid, data = d_fried_s)
```


```{r}
#test the difference between prototypically big and neutral objects when the adjective is small
d_wilc_sbn <- d %>%
  filter(adj == "small")%>%
  filter(prototype_status != "small")%>%
  group_by(subid, verb, prototype_status) %>%
  summarise(zone = mean(num_checked))%>%
  spread(prototype_status, zone)

wilcox.test(d_wilc_sbn$big, d_wilc_sbn$neither, alternative = "l", paired = TRUE)
```

```{r}
#test the difference between prototypically neither and small objects when the adjective is small
d_wilc_sns <- d %>%
  filter(adj == "small")%>%
  filter(prototype_status != "big")%>%
  group_by(subid, verb, prototype_status) %>%
  summarise(zone = mean(num_checked))%>%
  spread(prototype_status, zone)

wilcox.test(d_wilc_sns$neither, d_wilc_sns$small, alternative = "l", paired = TRUE)
```

```{r}
#test the difference between prototypically big and small objects when the adjective is small
d_wilc_sbs <- d %>%
  filter(adj == "small")%>%
  filter(prototype_status != "neither")%>%
  group_by(subid, verb, prototype_status) %>%
  summarise(zone = mean(num_checked))%>%
  spread(prototype_status, zone)

wilcox.test(d_wilc_sbs$big, d_wilc_sbs$small, alternative = "l", paired = TRUE)
```

####Reaction times by prototypicality status for each adjective

```{r}
#create equivalent of Figure 3 -- reaction times for each adjective for each prototypicality group
d_graph <- d %>%
  group_by(prototype_status, adj) %>%
  summarise(mean_rt = mean(elapsed_first_click_ms), sems = sem(elapsed_first_click_ms), cis = ci95(elapsed_first_click_ms))



d_graph$adj <- factor(d_graph$adj)


levels(d_graph$adj)


ggplot(d_graph, aes(x=adj, y=mean_rt, fill = prototype_status)) + geom_bar(stat = "identity", position=position_dodge()) +
    geom_errorbar(aes(ymin=mean_rt-sems, ymax=mean_rt+sems),
                  width=.2, position=position_dodge(.9))

ggplot(d_graph, aes(x=adj, y=mean_rt, fill = prototype_status)) + geom_bar(stat = "identity", position=position_dodge()) +
    geom_errorbar(aes(ymin=mean_rt-cis, ymax=mean_rt+cis),
                  width=.2, position=position_dodge(.9))
```

![Original graph of reaction times for each adjective for each prototypicality group](figures/trib-fig-3-rts.png)

```{r}
#test the difference between RTs for prototypically big when the adjective is small and prototypically small objects when the adjective is big -- incompatible questions

small_incomp <- d %>%
  filter(adj == "small") %>%
  filter(prototype_status == "big")

big_comp <- d %>%
  filter(adj == "big") %>%
  filter(prototype_status == "big")

big_incomp <- d %>%
  filter(adj == "big") %>%
  filter(prototype_status == "small")

small_comp <- d %>%
  filter(adj == "small") %>%
  filter(prototype_status == "small") 

#wilcox.test(small_comp$elapsed_first_click_ms, small_incomp$elapsed_first_click_ms, alternative = "g", paired = TRUE)

wilcox.test(big_comp$elapsed_first_click_ms, big_incomp$elapsed_first_click_ms, alternative = "g", paired = TRUE)

#same test using subject means instead of raw data (which can't relly be paired and also gives errors when trials are removed so there are unequal numbers in the groups) 
small_test <- d%>%
  filter(adj == "small") %>%
  filter(prototype_status != "neither") %>%
  group_by(subid, verb, prototype_status) %>%
  summarize(mean_rt = mean(elapsed_first_click_ms)) %>%
  spread(prototype_status, mean_rt)

wilcox.test(small_test$small, small_test$big, alternative = "g", paired = TRUE)

big_test <- d%>%
  filter(adj == "big") %>%
  filter(prototype_status != "neither") %>%
  group_by(subid, verb, prototype_status) %>%
  summarize(mean_rt = mean(elapsed_first_click_ms)) %>%
  spread(prototype_status, mean_rt)

wilcox.test(big_test$big, big_test$small, alternative = "g", paired = TRUE)



```

```{r}
#test differnece between RTs for the adjective big and the adjective small, with the prediction that the processing of small is more cognitively demanding and therefore RTs should be longer. Tribushinina(2011) did not find a significant differnce.
d_rt <- d %>%
  group_by(subid, noun, dir, adj)%>%
  summarise(rt = elapsed_first_click_ms) %>%
  spread(adj, rt)

wilcox.test(d_rt$small, d_rt$big, alternative = "g", paired = TRUE)
```


```{r}
#test of difference between RTs on ascending and descending trials with the same adjective
d_rt_small <- d %>%
  filter(adj == "small") %>%
  group_by(subid, noun, dir)%>%
  summarise(rt = elapsed_first_click_ms) %>%
  spread(dir, rt)

wilcox.test(d_rt_small$asc, d_rt_small$desc, alternative = "l", paired = TRUE)

d_rt_big <- d %>%
  filter(adj == "big") %>%
  group_by(subid, noun, dir)%>%
  summarise(rt = elapsed_first_click_ms) %>%
  spread(dir, rt)

wilcox.test(d_rt_big$asc, d_rt_big$desc, alternative = "l", paired = TRUE)
```





###Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
